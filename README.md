# Home Sales Data Analysis with PySpark

## Overview

This project focuses on analyzing home sales data using PySpark, a powerful big data processing framework. The dataset contains information about home sales, including property details such as price, bedrooms, bathrooms, square footage, and more.

The analysis involves using PySpark's capabilities to perform various data operations, including filtering, aggregation, and querying. Additionally, we explore techniques such as data caching and partitioning for optimizing data processing.

## Analysis Tasks

The project covers various analysis tasks, including:

1. Loading the home sales data into a PySpark DataFrame.
2. Calculating average prices for specific types of homes.
3. Partitioning the data by the year of construction.
4. Caching and uncaching temporary tables for performance comparison.
5. Analyzing view ratings and average prices.
6. Reading and working with partitioned Parquet data.

## Conclusion

This project showcases the capabilities of PySpark for analyzing large datasets efficiently. It demonstrates techniques for optimizing data processing, including caching and partitioning, and provides insights into home sales data.
